在编程中,数据清洗(Data Cleaning)通常包括以下几个主要操作:

1. **处理缺失值(Missing Values)**
   - 填充缺失值(用均值、中位数、常量等)   replace_invalid_data   
   - 删除包含缺失值的行/列 filter_invalid_data 
   - 插值法(Interpolation)估算缺失值      
      
2. **去除重复数据(Duplicates)**
   - 完全重复的行/记录
   - 近似重复/模糊重复的行

3. **过滤异常值(Outliers)**
   - 基于统计学原理(如3σ原理)识别并处理异常值
   - 使用分位数等分位技术过滤极端值

4. **格式化数据(Formatting)**
   - 转换数据类型(如字符串转数值)
   - 标准化日期/时间格式
   - 大小写转换
   - 删除无用字符(如前后空格)

5. **规范化数据(Normalization)**
   - 归一化数据(缩放到[0,1]范围内)
   - 标准化数据(将特征值转换至均值为0、标准差为1的分布)

6. **解析/提取子数据(Parsing/Splitting)**
   - 从较大记录中提取子字段
   - 拆分日期时间为多字段
   - 正则表达式提取所需数据

7. **合并数据集(Merging Datasets)**
   - 连接多个相关数据集
   - 处理数据冲突/交叉映射

8. **数据加注(Data Annotation)**
   - 为训练监督学习模型标注数据
   - 如为文本数据添加标签/类别

9. **换一数据(Deduplication)**
   - 检测并合并来自多个来源的重复记录

综上所述,数据清洗是一个系统性工程,目的是从原始数据中清理出高质量、规范化的数据集,为后续的数据分析和建模做好准备工作。



数据预处理是数据分析和机器学习任务中非常重要的一个步骤。除了数据清洗之外,数据预处理还包括以下几个主要操作:

1. **数据集成(Data Integration)**
   - 将来自不同来源的数据集合并成一个统一的数据集
   - 涉及处理数据冗余、数据值冲突等问题

2. **数据转换(Data Transformation)**
   - 对数据进行规范化或聚合等转换,使之符合进一步分析的要求
   - 包括数据规范化、数值属性的离散化或连续化、数据编码等

3. **数据减dimensionality(Data Reduction)**
   - 通过数据压缩、聚类和维数度量等方法减小数据维度
   - 目的是提高数据质量和可管理性

4. **特征选择(Feature Selection)**
   - 从原始特征集中选取最相关、最优的特征子集
   - 可以提高模型性能、可解释性,减少过拟合风险

5. **特征构建(Feature Engineering)** 
   - 从原始数据创建出新的特征
   - 可以捕获数据背后更深层次的模式

6. **数据采样(Data Sampling)**
   - 从大规模数据中选取一个合理的数据子集进行分析
   - 如分层采样、随机采样等

7. **数据分割(Data Partitioning)**
   - 将数据划分为训练集、验证集、测试集等
   - 用于模型训练、评估和选择

8. **数据失衡处理(Imbalanced Data Handling)**
   - 应对数据集中正负样本严重失衡的情况
   - 如过采样、欠采样等方法

数据预处理的关键是从原始数据中提取出高质量的特征和模式,为后续的模型训练和模式发现奠定基础。这是一个复杂而重要的过程,需要结合具体问题加以设计和优化。